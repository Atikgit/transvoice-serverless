import runpod
import torch
import torchaudio
import base64
import io
import os
import glob
import sherpa_onnx
import soundfile as sf
from transformers import SeamlessM4Tv2Model, AutoProcessor

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MODEL_PATH = "/model_data"
TTS_BASE_PATH = "/tts_models"

processor = None
model = None
tts_engines = {}

# 1. ‡¶≠‡¶æ‡¶∑‡¶æ ‡¶ï‡ßã‡¶° ‡¶Æ‡ßç‡¶Ø‡¶æ‡¶™‡¶ø‡¶Ç (RunPod 3-letter -> Model 2-letter)
ISO_MAP = {
    'ben': 'bn', 'hin': 'hi', 'ara': 'ar', 'urd': 'ur', 
    'spa': 'es', 'fra': 'fr', 'deu': 'de', 'ita': 'it',
    'jpn': 'ja', 'kor': 'ko', 'vie': 'vi', 'ind': 'id',
    'tur': 'tr', 'eng': 'en'
}

def load_seamless():
    global processor, model
    if model is None:
        print("Loading SeamlessM4T Engine...")
        processor = AutoProcessor.from_pretrained(MODEL_PATH)
        model = SeamlessM4Tv2Model.from_pretrained(MODEL_PATH).to(DEVICE)
        print("SeamlessM4T Loaded.")

def get_tts_engine(lang_code):
    if lang_code in tts_engines:
        return tts_engines[lang_code]

    print(f"üîç Searching TTS for: {lang_code}...")

    # ‡ßß. ‡¶™‡ßç‡¶∞‡¶•‡¶Æ‡ßá ‡¶∏‡¶∞‡¶æ‡¶∏‡¶∞‡¶ø ‡ß© ‡¶Ö‡¶ï‡ßç‡¶∑‡¶∞‡ßá‡¶∞ ‡¶ï‡ßã‡¶° ‡¶¶‡¶ø‡ßü‡ßá ‡¶´‡ßã‡¶≤‡ßç‡¶°‡¶æ‡¶∞ ‡¶ñ‡ßã‡¶Å‡¶ú‡¶æ
    search_pattern = os.path.join(TTS_BASE_PATH, f"vits-*-{lang_code}*")
    folders = glob.glob(search_pattern)

    # ‡ß®. ‡¶®‡¶æ ‡¶™‡ßá‡¶≤‡ßá ‡ß® ‡¶Ö‡¶ï‡ßç‡¶∑‡¶∞‡ßá‡¶∞ ‡¶ï‡ßã‡¶° ‡¶¶‡¶ø‡ßü‡ßá ‡¶ñ‡ßã‡¶Å‡¶ú‡¶æ (‡¶Ø‡ßá‡¶Æ‡¶® spa -> es)
    if not folders and lang_code in ISO_MAP:
        short_code = ISO_MAP[lang_code]
        search_pattern = os.path.join(TTS_BASE_PATH, f"vits-*-{short_code}*")
        folders = glob.glob(search_pattern)

    if not folders:
        print(f"‚ùå No TTS folder found for {lang_code}")
        return None

    folder_path = folders[0] # ‡¶™‡ßç‡¶∞‡¶•‡¶Æ ‡¶´‡ßã‡¶≤‡ßç‡¶°‡¶æ‡¶∞‡¶ü‡¶ø ‡¶®‡ßá‡¶ì‡ßü‡¶æ
    print(f"üìÇ Found Model Folder: {folder_path}")

    # ‡ß©. ‡¶´‡ßã‡¶≤‡ßç‡¶°‡¶æ‡¶∞‡ßá‡¶∞ ‡¶≠‡¶ø‡¶§‡¶∞ .onnx ‡¶´‡¶æ‡¶á‡¶≤ ‡¶ñ‡ßã‡¶Å‡¶ú‡¶æ
    onnx_files = glob.glob(os.path.join(folder_path, "*.onnx"))
    if not onnx_files:
        print("‚ùå No .onnx file found inside folder.")
        return None
    
    try:
        model_file = onnx_files[0]
        tokens_file = os.path.join(folder_path, "tokens.txt")
        data_dir = os.path.join(folder_path, "espeak-ng-data")
        
        config = sherpa_onnx.OfflineTtsVitsModelConfig(
            model=model_file,
            tokens=tokens_file,
            data_dir=data_dir if os.path.exists(data_dir) else ""
        )
        tts_config = sherpa_onnx.OfflineTtsConfig(
            model=sherpa_onnx.OfflineTtsModelConfig(vits=config)
        )
        engine = sherpa_onnx.OfflineTts(tts_config)
        tts_engines[lang_code] = engine
        print(f"‚úÖ Loaded Engine for {lang_code}")
        return engine
    except Exception as e:
        print(f"‚ùå Error loading engine: {e}")
        return None

def handler(job):
    load_seamless()
    job_input = job['input']
    
    audio_b64 = job_input.get("audio")
    # ‡¶ï‡ßç‡¶≤‡¶æ‡¶Ø‡¶º‡ßá‡¶®‡ßç‡¶ü ‡¶•‡ßá‡¶ï‡ßá ‡¶≠‡¶æ‡¶∑‡¶æ ‡¶ï‡ßã‡¶° ‡¶õ‡ßã‡¶ü ‡¶π‡¶æ‡¶§‡ßá‡¶∞ ‡¶Ö‡¶ï‡ßç‡¶∑‡¶∞‡ßá ‡¶®‡ßá‡¶ì‡ßü‡¶æ
    src_lang = job_input.get("src_lang", "eng").lower() 
    tgt_lang = job_input.get("tgt_lang", "ben").lower()

    if not audio_b64:
        return {"error": "No audio provided"}

    try:
        # A. Audio Decoding
        audio_bytes = base64.b64decode(audio_b64)
        audio_data, orig_freq = torchaudio.load(io.BytesIO(audio_bytes))
        if orig_freq != 16000:
            audio_data = torchaudio.transforms.Resample(orig_freq, 16000)(audio_data)

        # B. Translation (Text)
        # Seamless ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶∏‡¶æ‡¶ß‡¶æ‡¶∞‡¶£‡¶§ 3 ‡¶Ö‡¶ï‡ßç‡¶∑‡¶∞‡ßá‡¶∞ ‡¶ï‡ßã‡¶° ‡¶∏‡¶æ‡¶™‡ßã‡¶∞‡ßç‡¶ü ‡¶ï‡¶∞‡ßá (‡¶Ø‡ßá‡¶Æ‡¶® ben, spa)
        inputs = processor(audios=audio_data, src_lang=src_lang, return_tensors="pt").to(DEVICE)
        with torch.no_grad():
            tokens = model.generate(**inputs, tgt_lang=tgt_lang, generate_speech=False)
        translated_text = processor.decode(tokens[0].tolist(), skip_special_tokens=True)
        
        print(f"üìù Translated ({src_lang}->{tgt_lang}): {translated_text}")

        # C. TTS Generation
        engine = get_tts_engine(tgt_lang)
        audio_out_b64 = None
        
        if engine:
            # ‡¶∏‡ßç‡¶™‡¶ø‡¶° ‡ßß.‡ßß ‡¶∞‡¶æ‡¶ñ‡¶æ ‡¶π‡ßü‡ßá‡¶õ‡ßá ‡¶®‡ßç‡¶Ø‡¶æ‡¶ö‡¶æ‡¶∞‡¶æ‡¶≤ ‡¶∏‡¶æ‡¶â‡¶®‡ßç‡¶°‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø
            audio = engine.generate(translated_text, sid=0, speed=1.1)
            out_io = io.BytesIO()
            sf.write(out_io, audio.samples, audio.sample_rate, format='wav')
            audio_out_b64 = base64.b64encode(out_io.getvalue()).decode('utf-8')
        else:
            print(f"‚ö†Ô∏è Skipping TTS: Model not found for {tgt_lang}")

        return {
            "text_out": translated_text,
            "audio_out": audio_out_b64,
            "status": "success"
        }

    except Exception as e:
        print(f"üî• Error: {str(e)}")
        return {"error": str(e)}

runpod.serverless.start({"handler": handler})